[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nLithium, Sustainability and Batteries:  A new Era in Resource Management\n",
    "section": "",
    "text": "M.S. in Data Science and Analytics\n\n\n\nData Science & Analytics\n\n\nFinal Project\n\n\n\nLithium, Sustainability and Batteries:  A new Era in Resource Management\n\n\n\nBy: Maria Agustina Zuckerberg\n\n\nGU Net ID: maz53"
  },
  {
    "objectID": "eda/eda.html",
    "href": "eda/eda.html",
    "title": "Data Exploration",
    "section": "",
    "text": "Build out your website tab for exploratory data analysis"
  },
  {
    "objectID": "eda/eda.html#quick-look-at-the-data",
    "href": "eda/eda.html#quick-look-at-the-data",
    "title": "Data Exploration",
    "section": "Quick look at the data",
    "text": "Quick look at the data\n\n# Import seaborn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Apply the default theme\nsns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n\n# Load an example dataset\ntips = sns.load_dataset(\"tips\")\nprint(tips)\n\n     total_bill   tip     sex smoker   day    time  size\n0         16.99  1.01  Female     No   Sun  Dinner     2\n1         10.34  1.66    Male     No   Sun  Dinner     3\n2         21.01  3.50    Male     No   Sun  Dinner     3\n3         23.68  3.31    Male     No   Sun  Dinner     2\n4         24.59  3.61  Female     No   Sun  Dinner     4\n..          ...   ...     ...    ...   ...     ...   ...\n239       29.03  5.92    Male     No   Sat  Dinner     3\n240       27.18  2.00  Female    Yes   Sat  Dinner     2\n241       22.67  2.00    Male    Yes   Sat  Dinner     2\n242       17.82  1.75    Male     No   Sat  Dinner     2\n243       18.78  3.00  Female     No  Thur  Dinner     2\n\n[244 rows x 7 columns]"
  },
  {
    "objectID": "eda/eda.html#basic-visualization",
    "href": "eda/eda.html#basic-visualization",
    "title": "Data Exploration",
    "section": "Basic visualization",
    "text": "Basic visualization\n\n\n# Create a visualization\nsns.relplot(\n    data=tips,\n    x=\"total_bill\", y=\"tip\", col=\"time\",\n    hue=\"smoker\", style=\"smoker\", size=\"size\",\n)\n\nplt.show()"
  },
  {
    "objectID": "clustering/clustering.html",
    "href": "clustering/clustering.html",
    "title": "Clustering",
    "section": "",
    "text": "Build out your website tab for “clustering”"
  },
  {
    "objectID": "index.html#m.s.-in-data-science-and-analytics",
    "href": "index.html#m.s.-in-data-science-and-analytics",
    "title": "Data Science & Analytics",
    "section": "M.S. in Data Science and Analytics",
    "text": "M.S. in Data Science and Analytics"
  },
  {
    "objectID": "1_introduction.html",
    "href": "1_introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Overview\n\nGrowing concern about global warming has led to increased environmental awareness through the responsible use of finite resources in technological innovation. Lithium, the “white gold” of the 20th century, is now emerging as a critical element in enabling sustainable energy solutions.\nIt is predicted that 230 million electric cars, buses, vans and heavy trucks will be on the road by 2030. In 2019, the number of registered electric vehicles (EVs) increased from 5.6 million to 7.9 million globally, with significant growth in Europe and the United States.(see Dorn and Peyré 2020, 68) According to the International Energy Agency (IEA), an electric vehicle requires more than six times the mineral inputs of an internal combustion vehicle. According to the IEA, an electric vehicle requires more than six times the mineral inputs of an internal combustion vehicle. But EVs are just one type of product on the list. Lithium carbonate is the main ingredient in lithium-ion batteries found in cell phones, hybrid cars, electric bicycles and even large grid-scale storage batteries, as well as in other industries such as glass and ceramics manufacturing, metallurgy and pharmaceuticals.\nThe U.S. used to rely on other countries such as Australia or the Lithium Triangle (Argentina, Chile and Bolivia) for lithium supplies. Silver Peak, located in western Nevada, is currently the only lithium production site in the United States.(see. Stevens n.d.)\nIn the next figure we can observe the distribution of total global lithium production among the main lithium producing countries until 2020:\n\n\n  \n\n\nThe price of lithium has been on the rise as the energy and transportation sectors look to replace fossil fuels. Demand for the resource continues to outstrip supply. Although lithium is not a scarce resource, it’s a slow-moving industry; it can take about seven years to get a new mine up and running. These projects are capital intensive and require permits and environmental reviews.\nAnalysis of the resource production stages is often limited, as most of the existing scientific literature and news approaches the issue of lithium sustainability from a battery perspective. The role of metals and minerals production can be controversial, as it can be associated with negative environmental and social impacts. Often perceived as negative due to past project impacts on waste management, water scarcity, pollution and others. Some of the damaging effects to the ecosystem include transportation of the product, which requires the development of linear features such as electrical transmission lines, power lines and roads, disturbance of surface waterfowl, and disruption of habitat for terrestrial animals. Other effects of climate change include the nature of precipitation. Temperature is projected to rise steadily due to a decrease in precipitation.\nOn the opposite side, lithium is considered a key technological component for reducing air pollution in cities and creating lifestyles with low carbon footprints. For lithium-exporting countries, especially those in the lithium triangle, this creates economic opportunities and raises expectations for economic growth and improved living conditions for local groups. They have a positive impact on local communities by providing opportunities to improve the quality of life through program that improve access to health, education, business development, infrastructure and employment.(see. Petavratzi et al. 2022, 687) Employment opportunities play a central role. Although lithium mining is not particularly labor-intensive, some companies offer job training to help the local population become qualified to work in their operations.\n\n\n\nGoal\n\nIn order to overcome the challenges of lithium mining and reduce its environmental impact, it is important to consider a variety of strategies. These include improving sustainability, reducing the amount of energy and water used in the extraction process, and minimizing the amount of waste generated.\nThe aim of this project is to analyze the sustainability of lithium mining for battery manufacturing. The main topics of interest that will be addressed are the evolution of lithium production and price analysis, socio-economic impacts and perspective evolution, positive and negative environmental impacts implementing geographic information and strategies to optimize lithium-ion battery production.\n\n\n\nQuestions:\n\nHow has the distribution of the total global lithium production among the main lithium producing countries evolved over the past two decades?\nHow does lithium production volume correlate with changes in lithium demand, and can data-driven models help in predicting demand fluctuations?\nHow has public sentiment and opinion evolved regarding the increasing demand for lithium, and can text analysis reveal whether it is viewed positively due to sustainability or negatively due to environmental concerns?\nTo what extent can the use of geographic information (GIS) assist in identifying and mitigating the environmental and social impacts associated with lithium mining and extraction?\nHow have environmental regulations and sustainability initiatives impacted the lithium mining industry, and can data analysis quantify their impact on production?\nHas the price of lithium limited battery manufacturing growth in the past, and can data analysis reveal price trends and their impact on the industry?\nWhat is the historical relationship between lithium prices and battery manufacturing costs, and can data-driven models help identify opportunities for cost optimization?\nHow do government policies and incentives affect lithium production and its role in battery manufacturing?\nHow can data analytics quantify the impact of lithium production on the demand for and prices for other resources?\nHow can machine learning algorithms help predict future trends and challenges in the lithium mining and battery manufacturing industries, to promote sustainable practices and growth?\n\n\n\n\n\n\nReferences\n\nDorn, Felix M, and Fernando Ruiz Peyré. 2020. “Lithium as a Strategic Resource: Geopolitics, Industrialization, and Mining in Argentina.” Journal of Latin American Geography 19 (4): 68–90.\n\n\nPetavratzi, E, D Sanchez-Lopez, A Hughes, J Stacey, J Ford, and A Butcher. 2022. “The Impacts of Environmental, Social and Governance (ESG) Issues in Achieving Sustainable Lithium Supply in the Lithium Triangle.” Mineral Economics 35 (3-4): 673–99.\n\n\nStevens, Pippa. n.d. “Inside the Only Lithium Producer in the u.s., Which Provides the Critical Mineral Used in Batteries by Tesla, EV Makers.” Accessed 2022. https://www.cnbc.com/2022/10/14/lithium-for-tesla-evs-batteries-touring-silver-peak-nevada-.html."
  },
  {
    "objectID": "2_data_gathering.html#global-lithium-production",
    "href": "2_data_gathering.html#global-lithium-production",
    "title": "Data Gathering",
    "section": "Global Lithium Production",
    "text": "Global Lithium Production\nDataset that contains Lithium production lithium production in metric tonnes. The information is available from 1995 to 2022 y key lithium-producing countries."
  },
  {
    "objectID": "2_data_gathering.html#chinese-yuan-renminbi-to-u.s.-dollar-spot-exchange-rate",
    "href": "2_data_gathering.html#chinese-yuan-renminbi-to-u.s.-dollar-spot-exchange-rate",
    "title": "Data Gathering",
    "section": "Chinese Yuan Renminbi to U.S. Dollar Spot Exchange Rate",
    "text": "Chinese Yuan Renminbi to U.S. Dollar Spot Exchange Rate\n\nQUANTMOD API | R\nConsidering that the price of lithium is calculated in Yuan currency, and the analysis will be done in US dollars, the Quantmod API is used to obtain the daily exchange rates since 2020."
  },
  {
    "objectID": "2_data_gathering.html#lithium-news",
    "href": "2_data_gathering.html#lithium-news",
    "title": "Data Gathering",
    "section": "Lithium News",
    "text": "Lithium News"
  },
  {
    "objectID": "2_data_gathering.html#lithium-news---sentiment-analysis",
    "href": "2_data_gathering.html#lithium-news---sentiment-analysis",
    "title": "Data Gathering",
    "section": "Lithium News - Sentiment Analysis",
    "text": "Lithium News - Sentiment Analysis\n\nIBM Watson API | Python\nDescription"
  },
  {
    "objectID": "3_data_cleaning.html",
    "href": "3_data_cleaning.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "Overview\n\nIn this section, we will perform the data cleaning process. In order to improve the quality and accuracy of each dataset collected in the Data Gathering section, we apply several steps.\n\nBelow are the libraries used in this section:\n\n\nR Libraries\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa)\nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(readxl)\nlibrary(zoo)\n\n\n\n\nPython Libraries\nfrom datetime import date\nfrom dateutil.relativedelta import relativedelta\nfrom newsapi.newsapi_client import NewsApiClient\nimport pandas as pd\n\nimport json\nfrom ibm_watson import NaturalLanguageUnderstandingV1\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\nfrom ibm_watson.natural_language_understanding_v1 import Features, SentimentOptions\n\nimport os\n\n\n\n\nGlobal Lithium Production\n\nThe Global Lithium Production dataset was downloaded from the Our World in Data website as a csv file. Very few steps were applied to this dataset due to the quality of the original data.\n\n\nData Cleaning - Global Lithium Production\n\n\n\n\nGlobal Lithium Demand\n\nAdd description\n\n\n\nData Cleaning - Global Lithium Demand\n\n\n\nCommodity Price\n\nAdd description\n\n\n\nData Cleaning - Commodity Price\n\n\n\nLithium News\n\nAdd description\n\n\n\nData Cleaning - Lithium News"
  },
  {
    "objectID": "2_data_gathering.html",
    "href": "2_data_gathering.html",
    "title": "Data Gathering",
    "section": "",
    "text": "Global Lithium Production\nSource\nThe Global Lithium Production dataset was extracted from the Our World in Data website. The Energy Institute Statistical Review of World Energy analyzes data on world energy markets from the previous year, and Our World in Data consolidates data originally derived from the reports produced. The dataset provides information on global lithium production, including data for major producing countries and aggregations at the regional, continental, and global levels. Lithium production is measured in metric tons. The dataset covers the period from 1995 to 2022.\nWhile the dataset includes global data, this analysis will focus specifically on the evolution of lithium production, with a strong emphasis on the U.S. This approach allows for a more in-depth analysis of the growth and fluctuations of this resource, while assessing the impact on the economy.\n\n\n\n\n\n\n\n\nGlobal Lithium Demand Projection\nSource\nA key resource for our analysis is the Global Lithium Demand Projection dataset, which provides insight into the expected global demand for lithium. This data was originally published by the Comisión Chilena del Cobre in June 2023 in the paper “El mercado de litio: Desarrollo reciente y proyecciones al 2035”. Statista makes it available by condensing the the information into a dataset.\nIn recent years, the main source of lithium demand has come from electric vehicles. This is a trend that is expected to continue to grow progressively, so any projection of lithium demand will depend primarily on the growth of this sector. The demand projection methodology developed consists of several key steps. The first step is to obtain projected demand figures for electric vehicles. Second, it focuses on estimating the energy demand for lithium-ion batteries to be used in these vehicles. Third, the amount of lithium required for these batteries is calculated. Finally, this information is aggregated to present the projection of lithium demand specifically for electric vehicles, which is considered to be the most significant in the market. The information source for this analysis is Rho Motion, which was done in 2022.\nThis information is useful in two ways. On the one hand, it would be interesting to perform the same steps on raw data sets instead of using the analysis already done. On the other hand, this information serves as a key dataset for our assessment of future trends and the application of machine learning models.\n\n\n\n\nCommodity Price\n\nUranium\nCrude Oil\nNatural Gas\nCoal\nRenewable Energy\nBiofuels\nElectricity.\n\nThe commodity datasets play a key role in the goal of comparing lithium to other energy sources. This initial analysis focuses primarily on price comparisons, with future analyses to include consumption patterns. The commodities included in the analysis are Uranium, Crude Oil, Natural Gas, Coal, Renewables, Biofuels and Electricity, allowing for energy market assessments.\nCurrently, the dataset includes information related to the price of uranium over time. The data is obtained from the International Monetary Fund (IMF) and is available from January 2012, to December 2022.\n\n\n\n\n\n\n\nLithium News\nSource:  News API | Python\nThe Lithium News dataset is an essential resource for the project to understand the media perspective on the evolution of the lithium market. The News API allows the collection of text data from news articles related to lithium. This platform aggregates information from a variety of media sources. Given the focus of the project, the text data collection is primarily focused on U.S. media resources that have published articles in English. This approach ensures that the dataset provides relevant insights to address the project’s questions.\nThe date range for the API is variable, depending on the amount of data available at the time the scraping is done. To optimize data collection and maximize the date range for article collection, a special function has been developed to adjust the number of days. This approach allows for the most current and broadest data collection.\n\n\n\n\n\n\n\nLithium News - Sentiment Analysis\nSource:  IBM Watson API | Python\nThe Sentiment Analysis Dataset for the Lithium News is a crucial step in the analytical process of the project. It enriches the Lithium News dataset collected in the previous section. To improve our understanding of the lithium market perspective, we perform a sentiment analysis on the content of the news articles.\nTo do this, we will use the IBM Watson API, a tool designed to perform sentiment analysis on text data. The API allows us to process and analyze the text data and provide insights into the sentiment and tone of the articles.\nThe main objective of this analysis is to understand how the perspective on the lithium market has evolved. By evaluating the results obtained on the media news, we aim to determine whether the news articles have shown a bias towards a more positive or negative perspective. This allows us to identify potential shifts in sentiment that could impact the industry in the future."
  },
  {
    "objectID": "3_data_cleaning Python.html",
    "href": "3_data_cleaning Python.html",
    "title": "Data Gathering Python",
    "section": "",
    "text": "from datetime import date\nfrom dateutil.relativedelta import relativedelta"
  },
  {
    "objectID": "3_data_cleaning Python.html#lithium-news",
    "href": "3_data_cleaning Python.html#lithium-news",
    "title": "Data Gathering Python",
    "section": "Lithium News",
    "text": "Lithium News\n\nfrom newsapi.newsapi_client import NewsApiClient\nimport pandas as pd\n\ndate = date.today()\ndate_past = date - relativedelta(day=10)\n\nf = open('auth.k','r', encoding=\"utf-8\")\nak = f.readlines()\nf.close()\n\nnewsapi = NewsApiClient(api_key=ak[0])\n\nsources = newsapi.get_sources()\n\nsources = pd.DataFrame(sources['sources'])\n\nsources = sources[(sources['language'] == 'en') & (sources['country'] == 'us') & ~sources['category'].isin(['sports', 'entertainment', 'health'])]\n\n\ndf_sources = ', '.join(sources['id'].astype(str))\n\ndf_domains = ', '.join(sources['url'].astype(str))\n\nall_articles = newsapi.get_everything(q='lithium',\n                                      sources=str(df_sources),\n                                      domains=str(df_domains),\n                                      from_param=date_past,\n                                      to=date,\n                                      language='en',\n                                      sort_by='relevancy')\n\ndf_articles = pd.DataFrame(all_articles['articles'])\n\ndf_articles\n\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n\n\n\n\n\n\n\n\n\nsource\nauthor\ntitle\ndescription\nurl\nurlToImage\npublishedAt\ncontent\n\n\n\n\n0\n{'id': 'ars-technica', 'name': 'Ars Technica'}\nRyan Waniata\n25 of the most popular Amazon Prime Day deals ...\nAirPods, docking stations, Switch games, and m...\nhttps://arstechnica.com/shopping/2023/10/25-of...\nhttps://cdn.arstechnica.net/wp-content/uploads...\n2023-10-11T22:03:33Z\nEnlarge/ The case for AirPods Pro.\\r\\n5 with \\...\n\n\n1\n{'id': 'ars-technica', 'name': 'Ars Technica'}\nJonathan M. Gitlin\nThe 2023 Toyota Prius Prime is a mostly pleasa...\nToyota has helpfully increased the size of the...\nhttps://arstechnica.com/cars/2023/10/the-2023-...\nhttps://cdn.arstechnica.net/wp-content/uploads...\n2023-10-11T16:47:27Z\nEnlarge/ After a confusing mess for the last g...\n\n\n2\n{'id': 'newsweek', 'name': 'Newsweek'}\nAnna Skinner\nRare Metal Discovery Gives China a Boost\nThe find could widen China's lead in the elect...\nhttps://www.newsweek.com/rare-metal-discovery-...\nhttps://d.newsweek.com/en/full/2293356/rare-me...\n2023-10-11T16:56:55Z\nChinese scientists recently unearthed a rare o...\n\n\n3\n{'id': 'breitbart-news', 'name': 'Breitbart Ne...\nJohn Binder, John Binder\nCanadians Join UAW Strike as American Auto Wor...\nThousands of Canadian auto workers are joining...\nhttps://www.breitbart.com/politics/2023/10/10/...\nhttps://media.breitbart.com/media/2023/10/Gett...\n2023-10-10T19:21:20Z\nAfter thousands of Canadian auto workers joine...\n\n\n4\n{'id': 'cbs-news', 'name': 'CBS News'}\nJason R. Rich\nAmazon is practically giving away Blink video ...\nYou can get a Blink video doorbell for just $3...\nhttps://www.cbsnews.com/essentials/ring-in-50-...\nhttps://assets3.cbsnewsstatic.com/hub/i/r/2023...\n2023-10-10T11:25:08Z\nAmazon\\r\\nDuring the Amazon Prime Big Deal Day...\n\n\n5\n{'id': 'cbs-news', 'name': 'CBS News'}\nKaylyn McKenna\nWhen is the next Amazon Prime Day after the Oc...\nFind out when you can expect the next Amazon P...\nhttps://www.cbsnews.com/essentials/when-is-the...\nhttps://assets2.cbsnewsstatic.com/hub/i/r/2023...\n2023-10-11T16:24:00Z\nGetty Images\\r\\nShould you shop now, or just w...\n\n\n6\n{'id': 'cbs-news', 'name': 'CBS News'}\nFox Van Allen\nOur editors pick their favorite October Prime ...\nNot sure where to start at Amazon's October Pr...\nhttps://www.cbsnews.com/essentials/our-editors...\nhttps://assets3.cbsnewsstatic.com/hub/i/r/2023...\n2023-10-11T03:03:49Z\nAmazon\\r\\nThe Amazon Prime Big Deal Days sale,...\n\n\n7\n{'id': 'newsweek', 'name': 'Newsweek'}\nPandora Dewan\nToys Top List of 10 Most Common Types of Elect...\nNearly $57 billion of rare metals and raw mate...\nhttps://www.newsweek.com/toys-top-common-elect...\nhttps://d.newsweek.com/en/full/2292713/electro...\n2023-10-11T23:01:01Z\nEvery year, 7.3 billion electronic toys are th...\n\n\n8\n{'id': 'cbs-news', 'name': 'CBS News'}\nFox Van Allen\nThe most popular Amazon October Prime Day 2023...\nLooking for the best deals at Amazon's October...\nhttps://www.cbsnews.com/essentials/most-popula...\nhttps://assets2.cbsnewsstatic.com/hub/i/r/2023...\n2023-10-11T13:50:04Z\nAmazon\\r\\nThe Amazon Prime Big Deal Days sale,...\n\n\n9\n{'id': 'cbs-news', 'name': 'CBS News'}\nJennifer Martin, Kaylyn McKenna\nNail down Amazon October Prime Day 2023 saving...\nUpgrade your toolshed for less with these Amaz...\nhttps://www.cbsnews.com/essentials/dewalt-ryob...\nhttps://assets3.cbsnewsstatic.com/hub/i/r/2023...\n2023-10-10T14:04:28Z\nAmazon\\r\\nAmazon is offering some unbeatable t...\n\n\n10\n{'id': 'the-verge', 'name': 'The Verge'}\nAntonio G. Di Benedetto\nThe best October Prime Day deals you can get\nAmazon’s Prime Big Deal Days is like the early...\nhttps://www.theverge.com/23905078/amazon-octob...\nhttps://cdn.vox-cdn.com/thumbor/DpR_IUCoiu2kau...\n2023-10-10T12:00:43Z\nThe best October Prime Day deals you can get\\r...\n\n\n11\n{'id': 'the-verge', 'name': 'The Verge'}\nNilay Patel\nRivian CEO RJ Scaringe on ramping up R1T produ...\nRJ Scaringe sat down to discuss supply chain c...\nhttps://www.theverge.com/23908667/rivian-rj-sc...\nhttps://cdn.vox-cdn.com/thumbor/L0OtJjmuMXKGW9...\n2023-10-10T14:00:00Z\nPhoto illustration by Alex Parkin / The Verge\\...\n\n\n12\n{'id': 'reuters', 'name': 'Reuters'}\nReuters\nToyota, Idemitsu join hands to mass-produce al...\nToyota Motor &lt;a href=\"https://www.reuters.com/...\nhttps://www.reuters.com/business/autos-transpo...\nhttps://www.reuters.com/resizer/VW-QIBFgGOes6q...\n2023-10-12T04:06:43Z\nTOKYO, Oct 12 (Reuters) - Toyota Motor (7203.T...\n\n\n13\n{'id': 'the-verge', 'name': 'The Verge'}\nJustine Calma\nVapes, chargers, and other ‘invisible’ e-waste...\nChargers, vapes, and other small electronics m...\nhttps://www.theverge.com/2023/10/11/23912751/v...\nhttps://cdn.vox-cdn.com/thumbor/vonFLhBFKdRBiZ...\n2023-10-11T23:01:00Z\nVapes, chargers, and other invisible e-waste a...\n\n\n14\n{'id': 'the-verge', 'name': 'The Verge'}\nDan Seifert\nThe best October Prime Day deals available on ...\nThe final day of Prime Big Deal Days has arriv...\nhttps://www.theverge.com/2023/10/11/23912000/p...\nhttps://cdn.vox-cdn.com/thumbor/AmecFMQlrbkXsV...\n2023-10-11T11:58:57Z\nIllustration by Lucia Pham / The Verge\\r\\n\\n \\...\n\n\n\n\n\n\n\n\nsources\n\n\n\n\n\n\n\n\nid\nname\ndescription\nurl\ncategory\nlanguage\ncountry\n\n\n\n\n0\nabc-news\nABC News\nYour trusted source for breaking news, analysi...\nhttps://abcnews.go.com\ngeneral\nen\nus\n\n\n3\nal-jazeera-english\nAl Jazeera English\nNews, analysis from the Middle East and worldw...\nhttp://www.aljazeera.com\ngeneral\nen\nus\n\n\n6\nars-technica\nArs Technica\nThe PC enthusiast's resource. Power users and ...\nhttp://arstechnica.com\ntechnology\nen\nus\n\n\n8\nassociated-press\nAssociated Press\nThe AP delivers in-depth coverage on the inter...\nhttps://apnews.com/\ngeneral\nen\nus\n\n\n10\naxios\nAxios\nAxios are a new media company delivering vital...\nhttps://www.axios.com\ngeneral\nen\nus\n\n\n16\nbloomberg\nBloomberg\nBloomberg delivers business and markets news, ...\nhttp://www.bloomberg.com\nbusiness\nen\nus\n\n\n17\nbreitbart-news\nBreitbart News\nSyndicated news and opinion website providing ...\nhttp://www.breitbart.com\ngeneral\nen\nus\n\n\n18\nbusiness-insider\nBusiness Insider\nBusiness Insider is a fast-growing business si...\nhttp://www.businessinsider.com\nbusiness\nen\nus\n\n\n22\ncbs-news\nCBS News\nCBS News: dedicated to providing the best in j...\nhttp://www.cbsnews.com\ngeneral\nen\nus\n\n\n23\ncnn\nCNN\nView the latest news and breaking news today f...\nhttp://us.cnn.com\ngeneral\nen\nus\n\n\n25\ncrypto-coins-news\nCrypto Coins News\nProviding breaking cryptocurrency news - focus...\nhttps://www.ccn.com\ntechnology\nen\nus\n\n\n29\nengadget\nEngadget\nEngadget is a web magazine with obsessive dail...\nhttps://www.engadget.com\ntechnology\nen\nus\n\n\n36\nfortune\nFortune\nFortune 500 Daily and Breaking Business News\nhttp://fortune.com\nbusiness\nen\nus\n\n\n38\nfox-news\nFox News\nBreaking News, Latest News and Current News fr...\nhttp://www.foxnews.com\ngeneral\nen\nus\n\n\n41\ngoogle-news\nGoogle News\nComprehensive, up-to-date news coverage, aggre...\nhttps://news.google.com\ngeneral\nen\nus\n\n\n55\nhacker-news\nHacker News\nHacker News is a social news website focusing ...\nhttps://news.ycombinator.com\ntechnology\nen\nus\n\n\n73\nmsnbc\nMSNBC\nBreaking news and in-depth analysis of the hea...\nhttp://www.msnbc.com\ngeneral\nen\nus\n\n\n76\nnational-geographic\nNational Geographic\nReporting our world daily: original nature and...\nhttp://news.nationalgeographic.com\nscience\nen\nus\n\n\n77\nnational-review\nNational Review\nNational Review: Conservative News, Opinion, P...\nhttps://www.nationalreview.com/\ngeneral\nen\nus\n\n\n78\nnbc-news\nNBC News\nBreaking news, videos, and the latest top stor...\nhttp://www.nbcnews.com\ngeneral\nen\nus\n\n\n80\nnew-scientist\nNew Scientist\nBreaking science and technology news from arou...\nhttps://www.newscientist.com/section/news\nscience\nen\nus\n\n\n82\nnewsweek\nNewsweek\nNewsweek provides in-depth analysis, news and ...\nhttps://www.newsweek.com\ngeneral\nen\nus\n\n\n83\nnew-york-magazine\nNew York Magazine\nNYMAG and New York magazine cover the new, the...\nhttp://nymag.com\ngeneral\nen\nus\n\n\n84\nnext-big-future\nNext Big Future\nCoverage of science and technology that have t...\nhttps://www.nextbigfuture.com\nscience\nen\nus\n\n\n88\npolitico\nPolitico\nPolitical news about Congress, the White House...\nhttps://www.politico.com\ngeneral\nen\nus\n\n\n91\nrecode\nRecode\nGet the latest independent tech news, reviews ...\nhttp://www.recode.net\ntechnology\nen\nus\n\n\n92\nreddit-r-all\nReddit /r/all\nReddit is an entertainment, social news networ...\nhttps://www.reddit.com/r/all\ngeneral\nen\nus\n\n\n93\nreuters\nReuters\nReuters.com brings you the latest news from ar...\nhttp://www.reuters.com\ngeneral\nen\nus\n\n\n102\ntechcrunch\nTechCrunch\nTechCrunch is a leading technology media prope...\nhttps://techcrunch.com\ntechnology\nen\nus\n\n\n104\ntechradar\nTechRadar\nThe latest technology news and reviews, coveri...\nhttp://www.techradar.com\ntechnology\nen\nus\n\n\n105\nthe-american-conservative\nThe American Conservative\nRealism and reform. A new voice for a new gene...\nhttp://www.theamericanconservative.com/\ngeneral\nen\nus\n\n\n107\nthe-hill\nThe Hill\nThe Hill is a top US political website, read b...\nhttp://thehill.com\ngeneral\nen\nus\n\n\n109\nthe-huffington-post\nThe Huffington Post\nThe Huffington Post is a politically liberal A...\nhttp://www.huffingtonpost.com\ngeneral\nen\nus\n\n\n113\nthe-next-web\nThe Next Web\nThe Next Web is one of the world’s largest onl...\nhttp://thenextweb.com\ntechnology\nen\nus\n\n\n116\nthe-verge\nThe Verge\nThe Verge covers the intersection of technolog...\nhttp://www.theverge.com\ntechnology\nen\nus\n\n\n117\nthe-wall-street-journal\nThe Wall Street Journal\nWSJ online coverage of breaking news and curre...\nhttp://www.wsj.com\nbusiness\nen\nus\n\n\n118\nthe-washington-post\nThe Washington Post\nBreaking news and analysis on politics, busine...\nhttps://www.washingtonpost.com\ngeneral\nen\nus\n\n\n119\nthe-washington-times\nThe Washington Times\nThe Washington Times delivers breaking news an...\nhttps://www.washingtontimes.com/\ngeneral\nen\nus\n\n\n120\ntime\nTime\nBreaking news and analysis from TIME.com. Poli...\nhttp://time.com\ngeneral\nen\nus\n\n\n121\nusa-today\nUSA Today\nGet the latest national, international, and po...\nhttp://www.usatoday.com/news\ngeneral\nen\nus\n\n\n122\nvice-news\nVice News\nVice News is Vice Media, Inc.'s current affair...\nhttps://news.vice.com\ngeneral\nen\nus\n\n\n123\nwired\nWired\nWired is a monthly American magazine, publishe...\nhttps://www.wired.com\ntechnology\nen\nus"
  },
  {
    "objectID": "3_data_cleaning Python.html#ibm-watson---sentiment-analysis",
    "href": "3_data_cleaning Python.html#ibm-watson---sentiment-analysis",
    "title": "Data Gathering Python",
    "section": "IBM Watson - Sentiment Analysis",
    "text": "IBM Watson - Sentiment Analysis\n\n# pip install xlsxwriter\n#pip install xlrd\n#pip install openpyxl\n\nimport json\nfrom ibm_watson import NaturalLanguageUnderstandingV1\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\nfrom ibm_watson.natural_language_understanding_v1 import Features, SentimentOptions\n\nimport os\n\n\ndf_content = pd.DataFrame(df_articles, columns=['source', 'content', 'publishedAt'])\ndf_content['source'] = df_content['source'].apply(lambda x: x['id'])\n\nauthenticator = IAMAuthenticator('_4YE1Qj6PFjke1zYsp7Kapgfu5laaaBE1E_ZUw1IiUPa')\nnatural_language_understanding = NaturalLanguageUnderstandingV1(\n    version='2020-08-01',\n    authenticator=authenticator\n)\n\nnatural_language_understanding.set_service_url('https://api.us-south.natural-language-understanding.watson.cloud.ibm.com/instances/8b0909d1-3768-4c54-b80d-b9817610e36d')\n\n#IBM Watson\ni = 0\nibm_source = []\nibm_date = []\nibm_score = []\nibm_label = []\nfor index, row in df_content.iterrows():\n    response = natural_language_understanding.analyze(\n    text=row['content'], language = 'en',\n    features=Features(sentiment=SentimentOptions())).get_result()\n\n    s = row['source']\n    ibm_source.append(s)\n    d = row['publishedAt']\n    ibm_date.append(d)\n    x = response['sentiment']['document']['score']\n    x = round(x, 4)\n    ibm_score.append(x)\n    y = response['sentiment']['document']['label']\n    ibm_label.append(y)\n    # print(response['sentiment']['document']['score'])\n    # print(response['sentiment']['document']['label'])\n    # print(json.dumps(response, indent=2))\n\n    i=i+1   \n\nresults = {\"id\": ibm_source, \"ibm_date\": ibm_date, \"ibm_score\": ibm_score, \"ibm_label\": ibm_label}\n\nresults = pd.DataFrame(data = results)\n\n\nresults = results.merge(sources, how='left')\n\nresults = pd.DataFrame(results, columns=['name', 'category', 'ibm_score', 'ibm_label', 'ibm_date'])\n\nresults = results.rename(columns={'ibm_date': 'date'})\n\nresults['date'] = pd.to_datetime(results['date'])\n\nresults['date'] = results['date'].dt.date\n\nresults\n\n\n\n\n\n\n\n\nname\ncategory\nibm_score\nibm_label\ndate\n\n\n\n\n0\nArs Technica\ntechnology\n-0.8725\nnegative\n2023-10-11\n\n\n1\nArs Technica\ntechnology\n0.0000\nneutral\n2023-10-11\n\n\n2\nNewsweek\ngeneral\n0.8858\npositive\n2023-10-11\n\n\n3\nBreitbart News\ngeneral\n0.0000\nneutral\n2023-10-10\n\n\n4\nCBS News\ngeneral\n-0.6413\nnegative\n2023-10-10\n\n\n5\nCBS News\ngeneral\n-0.9248\nnegative\n2023-10-11\n\n\n6\nCBS News\ngeneral\n0.0000\nneutral\n2023-10-11\n\n\n7\nNewsweek\ngeneral\n-0.4266\nnegative\n2023-10-11\n\n\n8\nCBS News\ngeneral\n0.0000\nneutral\n2023-10-11\n\n\n9\nCBS News\ngeneral\n0.7472\npositive\n2023-10-10\n\n\n10\nThe Verge\ntechnology\n0.0000\nneutral\n2023-10-10\n\n\n11\nThe Verge\ntechnology\n0.0000\nneutral\n2023-10-10\n\n\n12\nReuters\ngeneral\n0.0000\nneutral\n2023-10-12\n\n\n13\nThe Verge\ntechnology\n-0.9079\nnegative\n2023-10-11\n\n\n14\nThe Verge\ntechnology\n0.3791\npositive\n2023-10-11"
  },
  {
    "objectID": "3_data_cleaning R.html",
    "href": "3_data_cleaning R.html",
    "title": "Data Gathering R",
    "section": "",
    "text": "Libraries\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(readxl)\nlibrary(zoo)"
  },
  {
    "objectID": "3_data_cleaning/3_5_news_api.html",
    "href": "3_data_cleaning/3_5_news_api.html",
    "title": "Lithium News",
    "section": "",
    "text": "Libraries\nfrom datetime import date\nfrom dateutil.relativedelta import relativedelta\nfrom newsapi.newsapi_client import NewsApiClient\nimport pandas as pd\n\nimport json\nfrom ibm_watson import NaturalLanguageUnderstandingV1\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\nfrom ibm_watson.natural_language_understanding_v1 import Features, SentimentOptions\n\nimport os\n\n\n\nNews API\n\n\nCode\ndate = date.today()\ndate_past = date - relativedelta(days=12)\n\nf = open('../auth.k','r', encoding=\"utf-8\")\nak = f.readlines()\nf.close()\n\nnewsapi = NewsApiClient(api_key=ak[0])\n\nsources = newsapi.get_sources()\n\nsources = pd.DataFrame(sources['sources'])\n\nsources = sources[(sources['language'] == 'en') & (sources['country'] == 'us') & ~sources['category'].isin(['sports', 'entertainment', 'health'])]\n\nsources.head(10)\n\n\n\n\n\n\n\n\n\nid\nname\ndescription\nurl\ncategory\nlanguage\ncountry\n\n\n\n\n0\nabc-news\nABC News\nYour trusted source for breaking news, analysi...\nhttps://abcnews.go.com\ngeneral\nen\nus\n\n\n3\nal-jazeera-english\nAl Jazeera English\nNews, analysis from the Middle East and worldw...\nhttp://www.aljazeera.com\ngeneral\nen\nus\n\n\n6\nars-technica\nArs Technica\nThe PC enthusiast's resource. Power users and ...\nhttp://arstechnica.com\ntechnology\nen\nus\n\n\n8\nassociated-press\nAssociated Press\nThe AP delivers in-depth coverage on the inter...\nhttps://apnews.com/\ngeneral\nen\nus\n\n\n10\naxios\nAxios\nAxios are a new media company delivering vital...\nhttps://www.axios.com\ngeneral\nen\nus\n\n\n16\nbloomberg\nBloomberg\nBloomberg delivers business and markets news, ...\nhttp://www.bloomberg.com\nbusiness\nen\nus\n\n\n17\nbreitbart-news\nBreitbart News\nSyndicated news and opinion website providing ...\nhttp://www.breitbart.com\ngeneral\nen\nus\n\n\n18\nbusiness-insider\nBusiness Insider\nBusiness Insider is a fast-growing business si...\nhttp://www.businessinsider.com\nbusiness\nen\nus\n\n\n22\ncbs-news\nCBS News\nCBS News: dedicated to providing the best in j...\nhttp://www.cbsnews.com\ngeneral\nen\nus\n\n\n23\ncnn\nCNN\nView the latest news and breaking news today f...\nhttp://us.cnn.com\ngeneral\nen\nus\n\n\n\n\n\n\n\n\n\nCode\ndf_sources = ', '.join(sources['id'].astype(str))\n\ndf_domains = ', '.join(sources['url'].astype(str))\n\nall_articles = newsapi.get_everything(q='lithium',\n                                      sources=str(df_sources),\n                                      domains=str(df_domains),\n                                      from_param=date_past,\n                                      to=date,\n                                      language='en',\n                                      sort_by='relevancy')\n\ndf_articles = pd.DataFrame(all_articles['articles'])\n\ndf_articles.head(10)\n\n\n\n\n\n\n\n\n\nsource\nauthor\ntitle\ndescription\nurl\nurlToImage\npublishedAt\ncontent\n\n\n\n\n0\n{'id': 'wired', 'name': 'Wired'}\nGrace Browne, Matt Reynolds\nHere’s the Truth Behind the Biggest (and Dumbe...\nYes, charging your phone overnight is bad for ...\nhttps://www.wired.com/story/how-to-improve-bat...\nhttps://media.wired.com/photos/653b8f898ed7be7...\n2023-10-27T11:00:00Z\nIn lithium-ion batteries, thats no longer the ...\n\n\n1\n{'id': 'the-verge', 'name': 'The Verge'}\nAndrew J. Hawkins\nFord hits the brakes on $12 billion in EV spen...\nFord is pausing about $12 billion in spending ...\nhttps://www.theverge.com/2023/10/26/23934172/f...\nhttps://cdn.vox-cdn.com/thumbor/LpKbkjEO0XFAxX...\n2023-10-27T00:16:44Z\nFord hits the brakes on $12 billion in EV spen...\n\n\n2\n{'id': 'ars-technica', 'name': 'Ars Technica'}\nJonathan M. Gitlin\nA giant battery gives this new school bus a 30...\nThe Type-D school bus uses a 387 kWh lithium i...\nhttps://arstechnica.com/cars/2023/10/this-elec...\nhttps://cdn.arstechnica.net/wp-content/uploads...\n2023-10-31T11:00:53Z\nEnlarge/ GreenPower has given its class-D elec...\n\n\n3\n{'id': 'business-insider', 'name': 'Business I...\nNathan Rennolds\nChina's led the EV race – but it may be runnin...\nThe world has woken up to China's control over...\nhttps://www.businessinsider.com/electric-cars-...\nhttps://i.insider.com/652eba9496f7540cd05e9155...\n2023-10-22T09:43:12Z\nWuling Hongguang Mini EVs on display at the Sh...\n\n\n4\n{'id': 'the-next-web', 'name': 'The Next Web'}\nIoanna Lykiardopoulou\nStartup bags €8.5M to bolster Europe’s EV batt...\nIn a big boost to sustainable mobility, 130 mi...\nhttps://thenextweb.com/news/startup-to-bolster...\nhttps://img-cdn.tnwcdn.com/image/tnw-blurple?f...\n2023-10-24T04:03:53Z\nIn a big boost to sustainable mobility, 130 mi...\n\n\n5\n{'id': 'the-next-web', 'name': 'The Next Web'}\nSiôn Geschwindt\nNorway’s AutoStore unveils next-gen electric w...\nNorwegian tech company AutoStore today unveile...\nhttps://thenextweb.com/news/norway-autostore-u...\nhttps://img-cdn.tnwcdn.com/image/tnw-blurple?f...\n2023-10-23T04:00:52Z\nNorwegian tech company AutoStore today unveile...\n\n\n6\n{'id': 'engadget', 'name': 'Engadget'}\nAndrew Tarantola\nNASA's John Mather keeps redefining our unders...\nSpace isn't hard only on account of the rocket...\nhttps://www.engadget.com/inside-the-star-facto...\nhttps://s.yimg.com/ny/api/res/1.2/pcPe4lUVbQVQ...\n2023-10-22T14:30:46Z\nSpace isn't hard only on account of the rocket...\n\n\n7\n{'id': 'business-insider', 'name': 'Business I...\nJenny McGrath\nWhy we don't have fusion power plants yet, and...\nTrying to create a fusion reaction on Earth is...\nhttps://www.businessinsider.com/why-no-fusion-...\nhttps://i.insider.com/6531858096f7540cd060d9a2...\n2023-10-29T12:19:01Z\nThe National Spherical Torus Experiment-Upgrad...\n\n\n8\n{'id': 'cbs-news', 'name': 'CBS News'}\nKate Gibson\nFeds warn against using Toos electric scooters...\nThe U.S. Consumer Product Safety Commission sa...\nhttps://www.cbsnews.com/news/product-recall-el...\nhttps://assets2.cbsnewsstatic.com/hub/i/r/2023...\n2023-10-23T19:46:00Z\nRiders of Toos Elite 60-volt electric scooters...\n\n\n9\n{'id': 'next-big-future', 'name': 'Next Big Fu...\nBrian Wang\nBetter EV Batteries and a Glut of Batteries Sh...\nCATL’s new Shenxing ultra-fast charging iron L...\nhttps://www.nextbigfuture.com/2023/10/better-e...\nhttps://nextbigfuture.s3.amazonaws.com/uploads...\n2023-10-25T15:47:05Z\nBrian Wang is a Futurist Thought Leader and a ...\n\n\n\n\n\n\n\n\n\n\nIBM Watson - Sentiment Analysis\n\n\nCode\ndf_content = pd.DataFrame(df_articles, columns=['source', 'content', 'publishedAt'])\ndf_content['source'] = df_content['source'].apply(lambda x: x['id'])\n\nauthenticator = IAMAuthenticator('_4YE1Qj6PFjke1zYsp7Kapgfu5laaaBE1E_ZUw1IiUPa')\nnatural_language_understanding = NaturalLanguageUnderstandingV1(\n    version='2020-08-01',\n    authenticator=authenticator\n)\n\nnatural_language_understanding.set_service_url('https://api.us-south.natural-language-understanding.watson.cloud.ibm.com/instances/8b0909d1-3768-4c54-b80d-b9817610e36d')\n\n#IBM Watson\ni = 0\nibm_source = []\nibm_date = []\nibm_score = []\nibm_label = []\nfor index, row in df_content.iterrows():\n    response = natural_language_understanding.analyze(\n    text=row['content'], language = 'en',\n    features=Features(sentiment=SentimentOptions())).get_result()\n\n    s = row['source']\n    ibm_source.append(s)\n    d = row['publishedAt']\n    ibm_date.append(d)\n    x = response['sentiment']['document']['score']\n    x = round(x, 4)\n    ibm_score.append(x)\n    y = response['sentiment']['document']['label']\n    ibm_label.append(y)\n    # print(response['sentiment']['document']['score'])\n    # print(response['sentiment']['document']['label'])\n    # print(json.dumps(response, indent=2))\n\n    i=i+1   \n\nresults = {\"id\": ibm_source, \"ibm_date\": ibm_date, \"ibm_score\": ibm_score, \"ibm_label\": ibm_label}\n\nresults = pd.DataFrame(data = results)\n\n\n\n\nCode\ndate = date.today()\n\nname = '../' + str(date) + '_results.csv'\n\nresults.to_csv(name, index=False)\n\nresults = results.merge(sources, how='left')\n\nresults = pd.DataFrame(results, columns=['name', 'category', 'ibm_score', 'ibm_label', 'ibm_date'])\n\nresults = results.rename(columns={'ibm_date': 'date'})\n\nresults['date'] = pd.to_datetime(results['date'])\n\nresults['date'] = results['date'].dt.date\n\nresults.head(10)\n\n\n\n\n\n\n\n\n\nname\ncategory\nibm_score\nibm_label\ndate\n\n\n\n\n0\nWired\ntechnology\n-0.5961\nnegative\n2023-10-27\n\n\n1\nThe Verge\ntechnology\n-0.8783\nnegative\n2023-10-27\n\n\n2\nArs Technica\ntechnology\n0.2886\npositive\n2023-10-31\n\n\n3\nBusiness Insider\nbusiness\n0.6452\npositive\n2023-10-22\n\n\n4\nThe Next Web\ntechnology\n0.6209\npositive\n2023-10-24\n\n\n5\nThe Next Web\ntechnology\n0.9080\npositive\n2023-10-23\n\n\n6\nEngadget\ntechnology\n0.0000\nneutral\n2023-10-22\n\n\n7\nBusiness Insider\nbusiness\n0.6035\npositive\n2023-10-29\n\n\n8\nCBS News\ngeneral\n-0.6290\nnegative\n2023-10-23\n\n\n9\nNext Big Future\nscience\n0.0000\nneutral\n2023-10-25"
  },
  {
    "objectID": "3_5_news_api.html",
    "href": "3_5_news_api.html",
    "title": "Lithium News",
    "section": "",
    "text": "Libraries\nfrom datetime import date\nfrom dateutil.relativedelta import relativedelta\nfrom newsapi.newsapi_client import NewsApiClient\nimport pandas as pd\n\nimport json\nfrom ibm_watson import NaturalLanguageUnderstandingV1\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\nfrom ibm_watson.natural_language_understanding_v1 import Features, SentimentOptions\n\nimport os\n\n\n\nNews API\n\n\nCode\ndate = date.today()\ndate_past = date - relativedelta(days=12)\n\nf = open('auth.k','r', encoding=\"utf-8\")\nak = f.readlines()\nf.close()\n\nnewsapi = NewsApiClient(api_key=ak[0])\n\nsources = newsapi.get_sources()\n\nsources = pd.DataFrame(sources['sources'])\n\nsources = sources[(sources['language'] == 'en') & (sources['country'] == 'us') & ~sources['category'].isin(['sports', 'entertainment', 'health'])]\n\nprint(sources.head(5))\n\n\n                    id                name  \\\n0             abc-news            ABC News   \n3   al-jazeera-english  Al Jazeera English   \n6         ars-technica        Ars Technica   \n8     associated-press    Associated Press   \n10               axios               Axios   \n\n                                          description  \\\n0   Your trusted source for breaking news, analysi...   \n3   News, analysis from the Middle East and worldw...   \n6   The PC enthusiast's resource. Power users and ...   \n8   The AP delivers in-depth coverage on the inter...   \n10  Axios are a new media company delivering vital...   \n\n                         url    category language country  \n0     https://abcnews.go.com     general       en      us  \n3   http://www.aljazeera.com     general       en      us  \n6     http://arstechnica.com  technology       en      us  \n8        https://apnews.com/     general       en      us  \n10     https://www.axios.com     general       en      us  \n\n\n\n\nCode\ndf_sources = ', '.join(sources['id'].astype(str))\n\ndf_domains = ', '.join(sources['url'].astype(str))\n\nall_articles = newsapi.get_everything(q='lithium',\n                                      sources=str(df_sources),\n                                      domains=str(df_domains),\n                                      from_param=date_past,\n                                      to=date,\n                                      language='en',\n                                      sort_by='relevancy')\n\ndf_articles = pd.DataFrame(all_articles['articles'])\n\ndf_articles.head(5)\n\n\n\n\n\n\n\n\n\nsource\nauthor\ntitle\ndescription\nurl\nurlToImage\npublishedAt\ncontent\n\n\n\n\n0\n{'id': 'abc-news', 'name': 'ABC News'}\nABC News\nWATCH: CCTV captures terrifying moment E-bike ...\nCCTV captures the moment an e-bike's lithium-i...\nhttps://abcnews.go.com/US/video/cctv-captures-...\nhttps://i.abcnewsfe.com/a/7d89adcc-4f6c-4a61-9...\n2023-10-04T11:03:13Z\n&lt;ul&gt;&lt;li&gt;Whats next for Russia? \\r\\n&lt;/li&gt;&lt;li&gt;Wh...\n\n\n1\n{'id': 'the-next-web', 'name': 'The Next Web'}\nIoanna Lykiardopoulou\nFrench startup bags €40M for unique CO2 batter...\nLyon-based Mecaware has raised €40mn in fundin...\nhttps://thenextweb.com/news/french-startup-40m...\nhttps://img-cdn.tnwcdn.com/image/tnw-blurple?f...\n2023-10-09T14:05:22Z\nLyon-based Mecaware has raised 40mn in funding...\n\n\n2\n{'id': 'ars-technica', 'name': 'Ars Technica'}\nRyan Waniata\n25 of the most popular Amazon Prime Day deals ...\nAirPods, docking stations, Switch games, and m...\nhttps://arstechnica.com/shopping/2023/10/25-of...\nhttps://cdn.arstechnica.net/wp-content/uploads...\n2023-10-11T22:03:33Z\nEnlarge/ The case for AirPods Pro.\\r\\n5 with \\...\n\n\n3\n{'id': 'abc-news', 'name': 'ABC News'}\nFARAI MUTSAKA Associated Press\nDeath toll in collapsed Zimbabwe gold mine exp...\nZimbabwe's vice president says the death toll ...\nhttps://abcnews.go.com/Business/wireStory/deat...\nhttps://i.abcnewsfe.com/a/9b5f9dbd-61d8-4bf8-8...\n2023-10-01T12:32:04Z\nHARARE, Zimbabwe -- The death toll from a shaf...\n\n\n4\n{'id': 'ars-technica', 'name': 'Ars Technica'}\nJonathan M. Gitlin\nThe 2023 Toyota Prius Prime is a mostly pleasa...\nToyota has helpfully increased the size of the...\nhttps://arstechnica.com/cars/2023/10/the-2023-...\nhttps://cdn.arstechnica.net/wp-content/uploads...\n2023-10-11T16:47:27Z\nEnlarge/ After a confusing mess for the last g...\n\n\n\n\n\n\n\n\n\n\nIBM Watson - Sentiment Analysis\n\n\nCode\ndf_content = pd.DataFrame(df_articles, columns=['source', 'content', 'publishedAt'])\ndf_content['source'] = df_content['source'].apply(lambda x: x['id'])\n\nauthenticator = IAMAuthenticator('_4YE1Qj6PFjke1zYsp7Kapgfu5laaaBE1E_ZUw1IiUPa')\nnatural_language_understanding = NaturalLanguageUnderstandingV1(\n    version='2020-08-01',\n    authenticator=authenticator\n)\n\nnatural_language_understanding.set_service_url('https://api.us-south.natural-language-understanding.watson.cloud.ibm.com/instances/8b0909d1-3768-4c54-b80d-b9817610e36d')\n\n#IBM Watson\ni = 0\nibm_source = []\nibm_date = []\nibm_score = []\nibm_label = []\nfor index, row in df_content.iterrows():\n    response = natural_language_understanding.analyze(\n    text=row['content'], language = 'en',\n    features=Features(sentiment=SentimentOptions())).get_result()\n\n    s = row['source']\n    ibm_source.append(s)\n    d = row['publishedAt']\n    ibm_date.append(d)\n    x = response['sentiment']['document']['score']\n    x = round(x, 4)\n    ibm_score.append(x)\n    y = response['sentiment']['document']['label']\n    ibm_label.append(y)\n    # print(response['sentiment']['document']['score'])\n    # print(response['sentiment']['document']['label'])\n    # print(json.dumps(response, indent=2))\n\n    i=i+1   \n\nresults = {\"id\": ibm_source, \"ibm_date\": ibm_date, \"ibm_score\": ibm_score, \"ibm_label\": ibm_label}\n\nresults = pd.DataFrame(data = results)\n\n\n\n\nCode\n# date = date.today()\n# name = str(date) + '_results.csv'\n\n# results.to_csv(name, index=False)\n\nresults = results.merge(sources, how='left')\n\nresults = pd.DataFrame(results, columns=['name', 'category', 'ibm_score', 'ibm_label', 'ibm_date'])\n\nresults = results.rename(columns={'ibm_date': 'date'})\n\nresults['date'] = pd.to_datetime(results['date'])\n\nresults['date'] = results['date'].dt.date\n\nresults\n\n\n\n\n\n\n\n\n\nname\ncategory\nibm_score\nibm_label\ndate\n\n\n\n\n0\nABC News\ngeneral\n-0.6553\nnegative\n2023-10-04\n\n\n1\nThe Next Web\ntechnology\n0.5855\npositive\n2023-10-09\n\n\n2\nArs Technica\ntechnology\n-0.8725\nnegative\n2023-10-11\n\n\n3\nABC News\ngeneral\n-0.7182\nnegative\n2023-10-01\n\n\n4\nArs Technica\ntechnology\n0.0000\nneutral\n2023-10-11\n\n\n5\nNext Big Future\nscience\n0.0000\nneutral\n2023-10-05\n\n\n6\nTechRadar\ntechnology\n-0.9441\nnegative\n2023-10-06\n\n\n7\nNewsweek\ngeneral\n0.8858\npositive\n2023-10-11\n\n\n8\nTechRadar\ntechnology\n0.0000\nneutral\n2023-10-05\n\n\n9\nCBS News\ngeneral\n-0.6365\nnegative\n2023-10-04\n\n\n10\nMSNBC\ngeneral\n0.0000\nneutral\n2023-10-06\n\n\n11\nABC News\ngeneral\n0.0000\nneutral\n2023-10-05\n\n\n12\nBreitbart News\ngeneral\n0.0000\nneutral\n2023-10-10\n\n\n13\nThe American Conservative\ngeneral\n-0.8355\nnegative\n2023-10-05\n\n\n14\nCBS News\ngeneral\n-0.6413\nnegative\n2023-10-10\n\n\n15\nCBS News\ngeneral\n0.6513\npositive\n2023-10-06\n\n\n16\nCBS News\ngeneral\n-0.9248\nnegative\n2023-10-11\n\n\n17\nCBS News\ngeneral\n0.0000\nneutral\n2023-10-11\n\n\n18\nABC News\ngeneral\n-0.7182\nnegative\n2023-10-01\n\n\n19\nNewsweek\ngeneral\n-0.3899\nnegative\n2023-10-03\n\n\n20\nNewsweek\ngeneral\n-0.4266\nnegative\n2023-10-11\n\n\n21\nEngadget\ntechnology\n0.8375\npositive\n2023-10-03\n\n\n22\nCBS News\ngeneral\n0.0000\nneutral\n2023-10-11\n\n\n23\nCBS News\ngeneral\n0.7472\npositive\n2023-10-10\n\n\n24\nNewsweek\ngeneral\n0.5167\npositive\n2023-10-03\n\n\n25\nThe Verge\ntechnology\n0.0000\nneutral\n2023-10-03\n\n\n26\nNew Scientist\nscience\n0.0000\nneutral\n2023-10-04\n\n\n27\nABC News\ngeneral\n0.0000\nneutral\n2023-10-02\n\n\n28\nNBC News\ngeneral\n0.0000\nneutral\n2023-10-04\n\n\n29\nThe Verge\ntechnology\n0.0000\nneutral\n2023-10-10\n\n\n30\nABC News\ngeneral\n0.0000\nneutral\n2023-10-02\n\n\n31\nFox News\ngeneral\n0.6282\npositive\n2023-10-05\n\n\n32\nBreitbart News\ngeneral\n-0.9107\nnegative\n2023-10-04\n\n\n33\nThe Verge\ntechnology\n0.0000\nneutral\n2023-10-10\n\n\n34\nReuters\ngeneral\n0.0000\nneutral\n2023-10-12\n\n\n35\nThe Verge\ntechnology\n-0.9079\nnegative\n2023-10-11\n\n\n36\nPolitico\ngeneral\n-0.8570\nnegative\n2023-10-02\n\n\n37\nTechCrunch\ntechnology\n0.8370\npositive\n2023-10-02\n\n\n38\nThe Verge\ntechnology\n0.3791\npositive\n2023-10-11"
  },
  {
    "objectID": "3_data_cleaning R.html#global-lithium-production",
    "href": "3_data_cleaning R.html#global-lithium-production",
    "title": "Data Gathering R",
    "section": "Global Lithium Production",
    "text": "Global Lithium Production\n\ndf_production &lt;- read.csv(\"../../data/00-raw-data/lithium-production.csv\")\n\ndf_production &lt;- df_production %&gt;% filter(nchar(Code) == 3)\n\nhead(df_production, n = 10)\n\nsummary(df_production)\n\n\nA data.frame: 10 × 4\n\n\n\nEntity\nCode\nYear\nLithium.production...kt\n\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n1\nArgentina\nARG\n1995\n8\n\n\n2\nArgentina\nARG\n1996\n8\n\n\n3\nArgentina\nARG\n1997\n8\n\n\n4\nArgentina\nARG\n1998\n1130\n\n\n5\nArgentina\nARG\n1999\n200\n\n\n6\nArgentina\nARG\n2000\n200\n\n\n7\nArgentina\nARG\n2001\n200\n\n\n8\nArgentina\nARG\n2002\n946\n\n\n9\nArgentina\nARG\n2003\n960\n\n\n10\nArgentina\nARG\n2004\n1970\n\n\n\n\n\n    Entity              Code                Year      Lithium.production...kt\n Length:224         Length:224         Min.   :1995   Min.   :    8          \n Class :character   Class :character   1st Qu.:2002   1st Qu.:  495          \n Mode  :character   Mode  :character   Median :2008   Median : 1500          \n                                       Mean   :2008   Mean   : 4591          \n                                       3rd Qu.:2015   3rd Qu.: 4735          \n                                       Max.   :2022   Max.   :61000"
  },
  {
    "objectID": "3_data_cleaning R.html#chinese-yuan-renminbi-to-u.s.-dollar-spot-exchange-rate",
    "href": "3_data_cleaning R.html#chinese-yuan-renminbi-to-u.s.-dollar-spot-exchange-rate",
    "title": "Data Gathering R",
    "section": "Chinese Yuan Renminbi to U.S. Dollar Spot Exchange Rate",
    "text": "Chinese Yuan Renminbi to U.S. Dollar Spot Exchange Rate\n\n\nLibraries\n# Set the start and end dates\nstart_date &lt;- \"2010-01-01\"\nend_date &lt;- \"2022-12-31\"\n\n# Define the symbol for CNY to USD exchange rate\nsymbol &lt;- \"DEXCHUS\"\n\n# Use getSymbols() to fetch the data\ngetSymbols(symbol, from = start_date, to = end_date, src = \"FRED\")\n\n# Access the data as a data frame\ndf_exchange_rate &lt;- as.data.frame(DEXCHUS)\n\ndf_exchange_rate &lt;- rownames_to_column(df_exchange_rate, var = \"DATE\")\n\ndf_exchange_rate$DATE &lt;- as.Date(df_exchange_rate$DATE)\n\n# Print the first few rows of the data\nhead(df_exchange_rate)\n\nsummary(df_exchange_rate)\n\n\n'DEXCHUS'\n\n\n\nA data.frame: 6 × 2\n\n\n\nDATE\nDEXCHUS\n\n\n\n&lt;date&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n2010-01-01\nNA\n\n\n2\n2010-01-04\n6.8273\n\n\n3\n2010-01-05\n6.8258\n\n\n4\n2010-01-06\n6.8272\n\n\n5\n2010-01-07\n6.8280\n\n\n6\n2010-01-08\n6.8274\n\n\n\n\n\n      DATE               DEXCHUS     \n Min.   :2010-01-01   Min.   :6.040  \n 1st Qu.:2013-04-02   1st Qu.:6.309  \n Median :2016-07-01   Median :6.504  \n Mean   :2016-07-01   Mean   :6.548  \n 3rd Qu.:2019-10-01   3rd Qu.:6.805  \n Max.   :2022-12-30   Max.   :7.305  \n                      NA's   :140"
  },
  {
    "objectID": "3_data_cleaning R.html#global-lithium-demand",
    "href": "3_data_cleaning R.html#global-lithium-demand",
    "title": "Data Gathering R",
    "section": "Global Lithium Demand",
    "text": "Global Lithium Demand\n\n#df &lt;- read_excel(\"./data/00-raw-data/lithium_price.xlsx\")"
  },
  {
    "objectID": "3_data_cleaning R.html#commodity-price",
    "href": "3_data_cleaning R.html#commodity-price",
    "title": "Data Gathering R",
    "section": "Commodity Price",
    "text": "Commodity Price\n\nUranium\n\n\nData Cleaning Code\ndf_commodity_price &lt;- read_excel(\"../../data/00-raw-data/commodity_price.xlsx\")\n\ndf_commodity_price &lt;- df_commodity_price %&gt;%\n  pivot_longer(cols = -c('...1'), \n               names_to = \"Month_Year\",\n               values_to = \"Price\")\n\ndf_commodity_price &lt;- df_commodity_price %&gt;% filter(!is.na(Price) & Price != \"\")\n\ndf_commodity_price$Month_Year &lt;- as.yearmon(df_commodity_price$Month_Year, format = \"%b %Y\")\n\ndf_commodity_price$Month_Year &lt;- format(df_commodity_price$Month_Year, \"%m-%Y\")\n\ndf_commodity_price$Month_Year &lt;- paste(\"01-\", df_commodity_price$Month_Year, sep = \"\")\n\ndf_commodity_price$Month_Year &lt;- as.Date(df_commodity_price$Month_Year, format = \"%d-%m-%Y\")\n\nnames(df_commodity_price) &lt;- c('Commodity', 'DATE', 'Price')\n\ndf_uranium_price &lt;- df_commodity_price %&gt;%\n  filter(Commodity == \"Uranium\")\n\n#df_uranium_price &lt;- head(df_uranium_price, n = 10)\n\n\n\nhead(df_uranium_price,20)\n\n\nA tibble: 20 × 3\n\n\nCommodity\nDATE\nPrice\n\n\n&lt;chr&gt;\n&lt;date&gt;\n&lt;dbl&gt;\n\n\n\n\nUranium\n2012-01-01\n52.31250\n\n\nUranium\n2012-02-01\n52.05556\n\n\nUranium\n2012-03-01\n51.28889\n\n\nUranium\n2012-04-01\n51.30000\n\n\nUranium\n2012-05-01\n51.88889\n\n\nUranium\n2012-06-01\n50.83333\n\n\nUranium\n2012-07-01\n50.35556\n\n\nUranium\n2012-08-01\n49.25000\n\n\nUranium\n2012-09-01\n47.72500\n\n\nUranium\n2012-10-01\n44.61111\n\n\nUranium\n2012-11-01\n41.50000\n\n\nUranium\n2012-12-01\n43.66667\n\n\nUranium\n2013-01-01\n42.75000\n\n\nUranium\n2013-02-01\n43.40625\n\n\nUranium\n2013-03-01\n42.28125\n\n\nUranium\n2013-04-01\n41.41250\n\n\nUranium\n2013-05-01\n40.60500\n\n\nUranium\n2013-06-01\n39.93750\n\n\nUranium\n2013-07-01\n38.02222\n\n\nUranium\n2013-08-01\n34.99416\n\n\n\n\n\n\n\nNatural Gas\n\n# Set the start and end dates\nstart_date &lt;- \"2012-01-01\"\nend_date &lt;- \"2022-12-31\"\n\n# Define the symbol for Gas Price to USD exchange rate\nsymbol &lt;- \"GASREGCOVW\"\n\n# Use getSymbols() to fetch the data\ngetSymbols(symbol, from = start_date, to = end_date, src = \"FRED\")\n\n# Access the data as a data frame\ndf_gas_price &lt;- as.data.frame(GASREGCOVW)\n\ndf_gas_price &lt;- rownames_to_column(df_gas_price, var = \"DATE\")\n\ndf_gas_price$DATE &lt;- as.Date(df_gas_price$DATE)\n\n# Print the first few rows of the data\nhead(df_gas_price, 10)\n\n'GASREGCOVW'\n\n\n\nA data.frame: 10 × 2\n\n\n\nDATE\nGASREGCOVW\n\n\n\n&lt;date&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n2012-01-02\n3.254\n\n\n2\n2012-01-09\n3.333\n\n\n3\n2012-01-16\n3.342\n\n\n4\n2012-01-23\n3.333\n\n\n5\n2012-01-30\n3.386\n\n\n6\n2012-02-06\n3.436\n\n\n7\n2012-02-13\n3.466\n\n\n8\n2012-02-20\n3.523\n\n\n9\n2012-02-27\n3.641\n\n\n10\n2012-03-05\n3.717\n\n\n\n\n\n\ndf_gas_price &lt;- df_gas_price %&gt;%\n    mutate(Year = year(DATE)) %&gt;%\n    mutate(Month = month(DATE)) %&gt;%\n    mutate(Day = day(DATE))\n\ndf_gas_price &lt;- df_gas_price %&gt;%\n    group_by(Year, Month) %&gt;%\n    filter(Day == min(Day)) %&gt;%\n    ungroup()\n\ndf_gas_price &lt;- df_gas_price %&gt;%\n    select(GASREGCOVW, Year, Month, Day)\n\ndf_gas_price &lt;- df_gas_price %&gt;%\n    mutate(DATE = paste(Year, Month, '01', sep = \"-\"))\n\ndf_gas_price$DATE &lt;- as.Date(df_gas_price$DATE)\n\ndf_gas_price &lt;- df_gas_price %&gt;%\n    select(GASREGCOVW, DATE)\n\nhead(df_gas_price, 10)\n\n\nA tibble: 10 × 2\n\n\nGASREGCOVW\nDATE\n\n\n&lt;dbl&gt;\n&lt;date&gt;\n\n\n\n\n3.254\n2012-01-01\n\n\n3.436\n2012-02-01\n\n\n3.717\n2012-03-01\n\n\n3.874\n2012-04-01\n\n\n3.718\n2012-05-01\n\n\n3.518\n2012-06-01\n\n\n3.291\n2012-07-01\n\n\n3.606\n2012-08-01\n\n\n3.797\n2012-09-01\n\n\n3.750\n2012-10-01\n\n\n\n\n\n\ndf_uranium_price &lt;- df_uranium_price %&gt;% select(DATE, Price)\n\nnames(df_uranium_price) &lt;- c('DATE', 'Uranium')\nnames(df_gas_price) &lt;- c('Natural Gas', 'DATE')\n\ndf_resource_price &lt;- merge(df_uranium_price, df_gas_price, by.x = 'DATE', by.y = 'DATE', all = TRUE)\n\nhead(df_resource_price, 10)\n\n\nA data.frame: 10 × 3\n\n\n\nDATE\nUranium\nNatural Gas\n\n\n\n&lt;date&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n2012-01-01\n52.31250\n3.254\n\n\n2\n2012-02-01\n52.05556\n3.436\n\n\n3\n2012-03-01\n51.28889\n3.717\n\n\n4\n2012-04-01\n51.30000\n3.874\n\n\n5\n2012-05-01\n51.88889\n3.718\n\n\n6\n2012-06-01\n50.83333\n3.518\n\n\n7\n2012-07-01\n50.35556\n3.291\n\n\n8\n2012-08-01\n49.25000\n3.606\n\n\n9\n2012-09-01\n47.72500\n3.797\n\n\n10\n2012-10-01\n44.61111\n3.750"
  },
  {
    "objectID": "3_data_cleaning/3_2_exchange_rate.html",
    "href": "3_data_cleaning/3_2_exchange_rate.html",
    "title": "Gas Price",
    "section": "",
    "text": "QUANTMOD API | R\n\n\nData Cleaning Code\n# Set the start and end dates\nstart_date &lt;- \"2000-01-01\"\nend_date &lt;- \"2022-12-31\"\n\n# Define the symbol for Gas Price to USD exchange rate\nsymbol &lt;- \"GASREGCOVW\"\n\n# Use getSymbols() to fetch the data\ngetSymbols(symbol, from = start_date, to = end_date, src = \"FRED\")\n\n\n[1] \"GASREGCOVW\"\n\n\nData Cleaning Code\n# Access the data as a data frame\ndf_exchange_rate &lt;- as.data.frame(GASREGCOVW)\n\ndf_exchange_rate &lt;- rownames_to_column(df_exchange_rate, var = \"DATE\")\n\ndf_exchange_rate$DATE &lt;- as.Date(df_exchange_rate$DATE)\n\n# Print the first few rows of the data\nhead(df_exchange_rate, n = 10)\n\n\n         DATE GASREGCOVW\n1  2000-01-03      1.260\n2  2000-01-10      1.252\n3  2000-01-17      1.268\n4  2000-01-24      1.307\n5  2000-01-31      1.307\n6  2000-02-07      1.319\n7  2000-02-14      1.350\n8  2000-02-21      1.400\n9  2000-02-28      1.413\n10 2000-03-06      1.490\n\n\n\n\n      DATE              GASREGCOVW   \n Min.   :2000-01-03   Min.   :1.042  \n 1st Qu.:2005-10-01   1st Qu.:1.933  \n Median :2011-06-30   Median :2.479  \n Mean   :2011-06-30   Mean   :2.510  \n 3rd Qu.:2017-03-28   3rd Qu.:3.078  \n Max.   :2022-12-26   Max.   :4.844"
  },
  {
    "objectID": "3_data_cleaning/3_3_lithium_demand.html",
    "href": "3_data_cleaning/3_3_lithium_demand.html",
    "title": "Global Lithium Demand",
    "section": "",
    "text": "Data Cleaning Code\ndf_demand &lt;- read_excel(\"../../../data/00-raw-data/global-lithium-demand.xlsx\", sheet=\"Data\")\n\nnames(df_demand) &lt;- c('Year', 'Demand')\n\ndf_demand &lt;- df_demand %&gt;% filter(!is.na(Demand) & Demand != \"\")\n\ndf_demand$Year &lt;- gsub(\"\\\\*\", \"\", df_demand$Year)\n\ndf_demand$Year &lt;- as.integer(df_demand$Year)\n\nhead(df_demand, n = 10)\n\n\n# A tibble: 10 × 2\n    Year Demand\n   &lt;int&gt;  &lt;dbl&gt;\n 1  2020    310\n 2  2021    508\n 3  2022    690\n 4  2023    917\n 5  2024   1072\n 6  2025   1257\n 7  2026   1433\n 8  2027   1628\n 9  2028   1861\n10  2029   2130\n\n\n\n\n      Year          Demand    \n Min.   :2020   Min.   : 310  \n 1st Qu.:2024   1st Qu.:1033  \n Median :2028   Median :1744  \n Mean   :2028   Mean   :1898  \n 3rd Qu.:2031   3rd Qu.:2749  \n Max.   :2035   Max.   :3829"
  },
  {
    "objectID": "3_data_cleaning/3_4_commodity_price.html",
    "href": "3_data_cleaning/3_4_commodity_price.html",
    "title": "Commodity Price",
    "section": "",
    "text": "Uranium Price\n\nBefore cleaning the dataset, the dataset had ### rows and # columns:\n\n\n\n\n\n\n\n\n\nData Gathering\n# Read csv file\ndf_commodity_price &lt;- read_excel(\"../../../data/00-raw-data/commodity_price.xlsx\")\n\n# Original dataset\nhead(df_commodity_price, n = 10)\n\n\n# A tibble: 10 × 265\n   ...1      `Jan 2012` ...3  `Feb 2012` ...5  `Mar 2012` ...7  `Apr 2012` ...9 \n   &lt;chr&gt;          &lt;dbl&gt; &lt;lgl&gt;      &lt;dbl&gt; &lt;lgl&gt;      &lt;dbl&gt; &lt;lgl&gt;      &lt;dbl&gt; &lt;lgl&gt;\n 1 Australi…     123.   NA        125.   NA        114.   NA        110.   NA   \n 2 South Af…     106.   NA        105.   NA        103.   NA        101.   NA   \n 3 Indonesi…      17.5  NA         16.7  NA         18.4  NA         19.6  NA   \n 4 Netherla…      12.3  NA         12.2  NA         12.5  NA         12.6  NA   \n 5 US, dome…       2.68 NA          2.50 NA          2.16 NA          1.95 NA   \n 6 Dubai         109.   NA        117.   NA        123.   NA        117.   NA   \n 7 U.K. Bre…     111.   NA        119.   NA        125.   NA        120.   NA   \n 8 West Tex…     100.   NA        102.   NA        106.   NA        103.   NA   \n 9 Agricult…      NA    NA         NA    NA         NA    NA         NA    NA   \n10 Cotton        101.   NA        101.   NA         99.5  NA        100.   NA   \n# ℹ 256 more variables: `May 2012` &lt;dbl&gt;, ...11 &lt;lgl&gt;, `Jun 2012` &lt;dbl&gt;,\n#   ...13 &lt;lgl&gt;, `Jul 2012` &lt;dbl&gt;, ...15 &lt;lgl&gt;, `Aug 2012` &lt;dbl&gt;, ...17 &lt;lgl&gt;,\n#   `Sep 2012` &lt;dbl&gt;, ...19 &lt;lgl&gt;, `Oct 2012` &lt;dbl&gt;, ...21 &lt;lgl&gt;,\n#   `Nov 2012` &lt;dbl&gt;, ...23 &lt;lgl&gt;, `Dec 2012` &lt;dbl&gt;, ...25 &lt;lgl&gt;,\n#   `Jan 2013` &lt;dbl&gt;, ...27 &lt;lgl&gt;, `Feb 2013` &lt;dbl&gt;, ...29 &lt;lgl&gt;,\n#   `Mar 2013` &lt;dbl&gt;, ...31 &lt;lgl&gt;, `Apr 2013` &lt;dbl&gt;, ...33 &lt;lgl&gt;,\n#   `May 2013` &lt;dbl&gt;, ...35 &lt;lgl&gt;, `Jun 2013` &lt;dbl&gt;, ...37 &lt;lgl&gt;, …\n\n\nDimensions:\n\n\n[1]  85 265\n\n\n\nData Cleaning Description.\n\n\n\nData Cleaning Code\ndf_commodity_price &lt;- read_excel(\"../../../data/00-raw-data/commodity_price.xlsx\")\n\ndf_commodity_price &lt;- df_commodity_price %&gt;%\n  pivot_longer(cols = -c('...1'), \n               names_to = \"Month_Year\",\n               values_to = \"Price\")\n\ndf_commodity_price &lt;- df_commodity_price %&gt;% filter(!is.na(Price) & Price != \"\")\n\ndf_commodity_price$Month_Year &lt;- as.yearmon(df_commodity_price$Month_Year, format = \"%b %Y\")\n\ndf_commodity_price$Month_Year &lt;- format(df_commodity_price$Month_Year, \"%m-%Y\")\n\ndf_commodity_price$Month_Year &lt;- paste(\"01-\", df_commodity_price$Month_Year, sep = \"\")\n\ndf_commodity_price$Month_Year &lt;- as.Date(df_commodity_price$Month_Year, format = \"%d-%m-%Y\")\n\nnames(df_commodity_price) &lt;- c('Commodity', 'DATE', 'Price')\n\ndf_uranium_price &lt;- df_commodity_price %&gt;%\n  filter(Commodity == \"Uranium\")\n\n\nCleaned Data:\n\n\n# A tibble: 10 × 3\n   Commodity DATE       Price\n   &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;\n 1 Uranium   2012-01-01  52.3\n 2 Uranium   2012-02-01  52.1\n 3 Uranium   2012-03-01  51.3\n 4 Uranium   2012-04-01  51.3\n 5 Uranium   2012-05-01  51.9\n 6 Uranium   2012-06-01  50.8\n 7 Uranium   2012-07-01  50.4\n 8 Uranium   2012-08-01  49.2\n 9 Uranium   2012-09-01  47.7\n10 Uranium   2012-10-01  44.6\n\n\nSummary:\n\n\n  Commodity              DATE                Price      \n Length:132         Min.   :2012-01-01   Min.   :18.57  \n Class :character   1st Qu.:2014-09-23   1st Qu.:25.57  \n Mode  :character   Median :2017-06-16   Median :32.14  \n                    Mean   :2017-06-16   Mean   :32.71  \n                    3rd Qu.:2020-03-08   3rd Qu.:38.26  \n                    Max.   :2022-12-01   Max.   :52.31  \n\n\nDimensions:\n\n\n[1] 132   3\n\n\n\n\nNatural Gas Price\n\nBefore cleaning the dataset, the dataset had ### rows and ### columns:\n\n\n\n\n\n\n\nData Gathering\n# Set the start and end dates\nstart_date &lt;- \"2000-01-01\"\nend_date &lt;- \"2022-12-31\"\n\n# Define the symbol for Gas Price to USD exchange rate\nsymbol &lt;- \"GASREGCOVW\"\n\n# Use getSymbols() to fetch the data\ngetSymbols(symbol, from = start_date, to = end_date, src = \"FRED\")\n\n\n[1] \"GASREGCOVW\"\n\n\nData Gathering\n# Access the data as a data frame\ndf_gas_price &lt;- as.data.frame(GASREGCOVW)\n\ndf_gas_price &lt;- rownames_to_column(df_gas_price, var = \"DATE\")\n\ndf_gas_price$DATE &lt;- as.Date(df_gas_price$DATE)\n\n\n\n\n         DATE GASREGCOVW\n1  2000-01-03      1.260\n2  2000-01-10      1.252\n3  2000-01-17      1.268\n4  2000-01-24      1.307\n5  2000-01-31      1.307\n6  2000-02-07      1.319\n7  2000-02-14      1.350\n8  2000-02-21      1.400\n9  2000-02-28      1.413\n10 2000-03-06      1.490\n\n\n\n\n      DATE              GASREGCOVW   \n Min.   :2000-01-03   Min.   :1.042  \n 1st Qu.:2005-10-01   1st Qu.:1.933  \n Median :2011-06-30   Median :2.479  \n Mean   :2011-06-30   Mean   :2.510  \n 3rd Qu.:2017-03-28   3rd Qu.:3.078  \n Max.   :2022-12-26   Max.   :4.844  \n\n\nDimensions:\n\n\n[1] 1200    2\n\n\n\nData Cleaning Description.\n\n\n\nData Cleaning\n# Separate the Date by terms\ndf_gas_price &lt;- df_gas_price %&gt;%\n    mutate(Year = year(DATE)) %&gt;%\n    mutate(Month = month(DATE)) %&gt;%\n    mutate(Day = day(DATE))\n\n\ndf_gas_price &lt;- df_gas_price %&gt;%\n    group_by(Year, Month) %&gt;%\n    filter(Day == min(Day)) %&gt;%\n    ungroup()\n\n\ndf_gas_price &lt;- df_gas_price %&gt;%\n    select(GASREGCOVW, Year, Month, Day)\n\n\ndf_gas_price &lt;- df_gas_price %&gt;%\n    mutate(DATE = paste(Year, Month, '01', sep = \"-\"))\n\n\ndf_gas_price$DATE &lt;- as.Date(df_gas_price$DATE)\n\n\ndf_gas_price &lt;- df_gas_price %&gt;%\n    select(GASREGCOVW, DATE)\n\n\nCleaned Data:\n\n\n# A tibble: 10 × 2\n   GASREGCOVW DATE      \n        &lt;dbl&gt; &lt;date&gt;    \n 1       1.26 2000-01-01\n 2       1.32 2000-02-01\n 3       1.49 2000-03-01\n 4       1.48 2000-04-01\n 5       1.39 2000-05-01\n 6       1.54 2000-06-01\n 7       1.61 2000-07-01\n 8       1.44 2000-08-01\n 9       1.50 2000-09-01\n10       1.50 2000-10-01\n\n\nSummary:\n\n\n   GASREGCOVW         DATE           \n Min.   :1.084   Min.   :2000-01-01  \n 1st Qu.:1.919   1st Qu.:2005-09-23  \n Median :2.485   Median :2011-06-16  \n Mean   :2.510   Mean   :2011-06-16  \n 3rd Qu.:3.089   3rd Qu.:2017-03-08  \n Max.   :4.702   Max.   :2022-12-01  \n\n\nDimensions:\n\n\n[1] 276   2\n\n\n\n\nResources Price\n\nData Cleaning Description.\n\n\n\nData Cleaning\ndf_uranium_price &lt;- df_uranium_price %&gt;% select(DATE, Price)\n\nnames(df_uranium_price) &lt;- c('DATE', 'Uranium')\n\nnames(df_gas_price) &lt;- c('Natural Gas', 'DATE')\n\ndf_resource_price &lt;- merge(df_uranium_price, df_gas_price, by.x = 'DATE', by.y = 'DATE', all = TRUE)\n\n\nCleaned Data:\n\n\n         DATE Uranium Natural Gas\n1  2000-01-01      NA       1.260\n2  2000-02-01      NA       1.319\n3  2000-03-01      NA       1.490\n4  2000-04-01      NA       1.478\n5  2000-05-01      NA       1.386\n6  2000-06-01      NA       1.535\n7  2000-07-01      NA       1.606\n8  2000-08-01      NA       1.437\n9  2000-09-01      NA       1.502\n10 2000-10-01      NA       1.498\n\n\nSummary:\n\n\n      DATE               Uranium       Natural Gas   \n Min.   :2000-01-01   Min.   :18.57   Min.   :1.084  \n 1st Qu.:2005-09-23   1st Qu.:25.57   1st Qu.:1.919  \n Median :2011-06-16   Median :32.14   Median :2.485  \n Mean   :2011-06-16   Mean   :32.71   Mean   :2.510  \n 3rd Qu.:2017-03-08   3rd Qu.:38.26   3rd Qu.:3.089  \n Max.   :2022-12-01   Max.   :52.31   Max.   :4.702  \n                      NA's   :144                    \n\n\nDimensions:\n\n\n[1] 276   3"
  },
  {
    "objectID": "3_data_cleaning/3_1_lithium_production.html",
    "href": "3_data_cleaning/3_1_lithium_production.html",
    "title": "Global Lithium Production",
    "section": "",
    "text": "Before cleaning the dataset, the dataset had 532 rows and 4 columns:\n\nEntity that represents the region/country of the information\nCode of the Entity\nYear the information was collected\nLithium production measured in tons.\n\n\n\n\nData Gathering\n# Read csv file\ndf_production &lt;- read.csv(\"../../../data/00-raw-data/lithium-production.csv\")\n\n# Original dataset\nhead(df_production, n = 10)\n\n\n   Entity Code Year Lithium.production...kt\n1  Africa      1995                     520\n2  Africa      1996                     500\n3  Africa      1997                     700\n4  Africa      1998                    1000\n5  Africa      1999                     700\n6  Africa      2000                     740\n7  Africa      2001                     700\n8  Africa      2002                     640\n9  Africa      2003                     480\n10 Africa      2004                     240\n\n\nDimensions:\n\n\n[1] 532   4\n\n\n\nThe data cleansing step performed on this dataset was to filter the rows to remove the nan from the Code column. This allows us to keep only the lithium production records for the countries in the dataset, removing the global and regional totals. In the next section we will plot the information and compare lithium production between countries over time.\nThe cleaned dataset has 224 rows and 4 columns. The available information was collected from 1995 to 2022.\n\n\n\nData Cleaning\n# Filter Code Column \ndf_production &lt;- df_production %&gt;% filter(nchar(Code) == 3)\n\n\nCleaned Data:\n\n\n      Entity Code Year Lithium.production...kt\n1  Argentina  ARG 1995                       8\n2  Argentina  ARG 1996                       8\n3  Argentina  ARG 1997                       8\n4  Argentina  ARG 1998                    1130\n5  Argentina  ARG 1999                     200\n6  Argentina  ARG 2000                     200\n7  Argentina  ARG 2001                     200\n8  Argentina  ARG 2002                     946\n9  Argentina  ARG 2003                     960\n10 Argentina  ARG 2004                    1970\n\n\nSummary:\n\n\n    Entity              Code                Year      Lithium.production...kt\n Length:224         Length:224         Min.   :1995   Min.   :    8          \n Class :character   Class :character   1st Qu.:2002   1st Qu.:  495          \n Mode  :character   Mode  :character   Median :2008   Median : 1500          \n                                       Mean   :2008   Mean   : 4591          \n                                       3rd Qu.:2015   3rd Qu.: 4735          \n                                       Max.   :2022   Max.   :61000          \n\n\nDimensions:\n\n\n[1] 224   4"
  },
  {
    "objectID": "4_eda/4_1_lithium_production.html",
    "href": "4_eda/4_1_lithium_production.html",
    "title": "Global Lithium Production",
    "section": "",
    "text": "Before cleaning the dataset, the dataset had 532 rows and 4 columns:\n\nEntity that represents the region/country of the information\nCode of the Entity\nYear the information was collected\nLithium production measured in tons.\n\n\n\n\nData Gathering\n# Read csv file\ndf_production &lt;- read.csv(\"../../../data/00-raw-data/lithium-production.csv\")\n\n# Original dataset\nhead(df_production, n = 10)\n\n\n   Entity Code Year Lithium.production...kt\n1  Africa      1995                     520\n2  Africa      1996                     500\n3  Africa      1997                     700\n4  Africa      1998                    1000\n5  Africa      1999                     700\n6  Africa      2000                     740\n7  Africa      2001                     700\n8  Africa      2002                     640\n9  Africa      2003                     480\n10 Africa      2004                     240\n\n\nDimensions:\n\n\n[1] 532   4\n\n\n\nThe data cleansing step performed on this dataset was to filter the rows to remove the nan from the Code column. This allows us to keep only the lithium production records for the countries in the dataset, removing the global and regional totals. In the next section we will plot the information and compare lithium production between countries over time.\nThe cleaned dataset has 224 rows and 4 columns. The available information was collected from 1995 to 2022.\n\n\n\nData Cleaning\n# Filter Code Column \ndf_production &lt;- df_production %&gt;% filter(nchar(Code) == 3)\n\n\nCleaned Data:\n\n\n      Entity Code Year Lithium.production...kt\n1  Argentina  ARG 1995                       8\n2  Argentina  ARG 1996                       8\n3  Argentina  ARG 1997                       8\n4  Argentina  ARG 1998                    1130\n5  Argentina  ARG 1999                     200\n6  Argentina  ARG 2000                     200\n7  Argentina  ARG 2001                     200\n8  Argentina  ARG 2002                     946\n9  Argentina  ARG 2003                     960\n10 Argentina  ARG 2004                    1970\n\n\nSummary:\n\n\n    Entity              Code                Year      Lithium.production...kt\n Length:224         Length:224         Min.   :1995   Min.   :    8          \n Class :character   Class :character   1st Qu.:2002   1st Qu.:  495          \n Mode  :character   Mode  :character   Median :2008   Median : 1500          \n                                       Mean   :2008   Mean   : 4591          \n                                       3rd Qu.:2015   3rd Qu.: 4735          \n                                       Max.   :2022   Max.   :61000          \n\n\nDimensions:\n\n\n[1] 224   4"
  },
  {
    "objectID": "4_eda/eda.html",
    "href": "4_eda/eda.html",
    "title": "Data Exploration",
    "section": "",
    "text": "Build out your website tab for exploratory data analysis"
  },
  {
    "objectID": "4_eda/eda.html#quick-look-at-the-data",
    "href": "4_eda/eda.html#quick-look-at-the-data",
    "title": "Data Exploration",
    "section": "Quick look at the data",
    "text": "Quick look at the data\n\n# Import seaborn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Apply the default theme\nsns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n\n# Load an example dataset\ntips = sns.load_dataset(\"tips\")\nprint(tips)\n\n     total_bill   tip     sex smoker   day    time  size\n0         16.99  1.01  Female     No   Sun  Dinner     2\n1         10.34  1.66    Male     No   Sun  Dinner     3\n2         21.01  3.50    Male     No   Sun  Dinner     3\n3         23.68  3.31    Male     No   Sun  Dinner     2\n4         24.59  3.61  Female     No   Sun  Dinner     4\n..          ...   ...     ...    ...   ...     ...   ...\n239       29.03  5.92    Male     No   Sat  Dinner     3\n240       27.18  2.00  Female    Yes   Sat  Dinner     2\n241       22.67  2.00    Male    Yes   Sat  Dinner     2\n242       17.82  1.75    Male     No   Sat  Dinner     2\n243       18.78  3.00  Female     No  Thur  Dinner     2\n\n[244 rows x 7 columns]"
  },
  {
    "objectID": "4_eda/eda.html#basic-visualization",
    "href": "4_eda/eda.html#basic-visualization",
    "title": "Data Exploration",
    "section": "Basic visualization",
    "text": "Basic visualization\n\n\n# Create a visualization\nsns.relplot(\n    data=tips,\n    x=\"total_bill\", y=\"tip\", col=\"time\",\n    hue=\"smoker\", style=\"smoker\", size=\"size\",\n)\n\nplt.show()"
  },
  {
    "objectID": "4_EDA_df_resources_prices.html",
    "href": "4_EDA_df_resources_prices.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "# Read csv file\ndf_production &lt;- read.csv(\"../../data/01-modified-data/clean_lithium-production.csv\")\n\n# Read csv file\ndf_demand &lt;- read.csv(\"../../data/01-modified-data/clean_lithium-demand.csv\")\n\n\ndf_production &lt;- df_production %&gt;% filter(df_production$Code == \"USA\")\n\ndf_production\n\n\nA data.frame: 28 × 4\n\n\nEntity\nCode\nYear\nLithium.production...kt\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\nUnited States\nUSA\n1995\n3500.000\n\n\nUnited States\nUSA\n1996\n4000.000\n\n\nUnited States\nUSA\n1997\n4000.000\n\n\nUnited States\nUSA\n1998\n1500.000\n\n\nUnited States\nUSA\n1999\n1500.000\n\n\nUnited States\nUSA\n2000\n1500.000\n\n\nUnited States\nUSA\n2001\n1500.000\n\n\nUnited States\nUSA\n2002\n1500.000\n\n\nUnited States\nUSA\n2003\n1500.000\n\n\nUnited States\nUSA\n2004\n1500.000\n\n\nUnited States\nUSA\n2005\n1500.000\n\n\nUnited States\nUSA\n2006\n1500.000\n\n\nUnited States\nUSA\n2007\n1500.000\n\n\nUnited States\nUSA\n2008\n1500.000\n\n\nUnited States\nUSA\n2009\n1500.000\n\n\nUnited States\nUSA\n2010\n1000.000\n\n\nUnited States\nUSA\n2011\n1000.000\n\n\nUnited States\nUSA\n2012\n1000.000\n\n\nUnited States\nUSA\n2013\n870.000\n\n\nUnited States\nUSA\n2014\n900.000\n\n\nUnited States\nUSA\n2015\n900.000\n\n\nUnited States\nUSA\n2016\n900.000\n\n\nUnited States\nUSA\n2017\n900.000\n\n\nUnited States\nUSA\n2018\n900.000\n\n\nUnited States\nUSA\n2019\n900.000\n\n\nUnited States\nUSA\n2020\n900.000\n\n\nUnited States\nUSA\n2021\n939.234\n\n\nUnited States\nUSA\n2022\n939.234"
  },
  {
    "objectID": "4_EDA_df_resources_prices.html#df_resources_prices",
    "href": "4_EDA_df_resources_prices.html#df_resources_prices",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "# Read csv file\ndf_production &lt;- read.csv(\"../../data/01-modified-data/clean_lithium-production.csv\")\n\n# Read csv file\ndf_demand &lt;- read.csv(\"../../data/01-modified-data/clean_lithium-demand.csv\")\n\n\ndf_production &lt;- df_production %&gt;% filter(df_production$Code == \"USA\")\n\ndf_production\n\n\nA data.frame: 28 × 4\n\n\nEntity\nCode\nYear\nLithium.production...kt\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\nUnited States\nUSA\n1995\n3500.000\n\n\nUnited States\nUSA\n1996\n4000.000\n\n\nUnited States\nUSA\n1997\n4000.000\n\n\nUnited States\nUSA\n1998\n1500.000\n\n\nUnited States\nUSA\n1999\n1500.000\n\n\nUnited States\nUSA\n2000\n1500.000\n\n\nUnited States\nUSA\n2001\n1500.000\n\n\nUnited States\nUSA\n2002\n1500.000\n\n\nUnited States\nUSA\n2003\n1500.000\n\n\nUnited States\nUSA\n2004\n1500.000\n\n\nUnited States\nUSA\n2005\n1500.000\n\n\nUnited States\nUSA\n2006\n1500.000\n\n\nUnited States\nUSA\n2007\n1500.000\n\n\nUnited States\nUSA\n2008\n1500.000\n\n\nUnited States\nUSA\n2009\n1500.000\n\n\nUnited States\nUSA\n2010\n1000.000\n\n\nUnited States\nUSA\n2011\n1000.000\n\n\nUnited States\nUSA\n2012\n1000.000\n\n\nUnited States\nUSA\n2013\n870.000\n\n\nUnited States\nUSA\n2014\n900.000\n\n\nUnited States\nUSA\n2015\n900.000\n\n\nUnited States\nUSA\n2016\n900.000\n\n\nUnited States\nUSA\n2017\n900.000\n\n\nUnited States\nUSA\n2018\n900.000\n\n\nUnited States\nUSA\n2019\n900.000\n\n\nUnited States\nUSA\n2020\n900.000\n\n\nUnited States\nUSA\n2021\n939.234\n\n\nUnited States\nUSA\n2022\n939.234"
  },
  {
    "objectID": "4_EDA_df_lithium.html",
    "href": "4_EDA_df_lithium.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "# Read csv file\ndf_production &lt;- read.csv(\"../../data/01-modified-data/clean_lithium-production.csv\")\n\n# Read csv file\ndf_demand &lt;- read.csv(\"../../data/01-modified-data/clean_lithium-demand.csv\")\n\n\ndf_production &lt;- df_production %&gt;% filter(df_production$Code == \"USA\")\n\ndf_production\n\n\nA data.frame: 28 × 4\n\n\nEntity\nCode\nYear\nLithium.production...kt\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\nUnited States\nUSA\n1995\n3500.000\n\n\nUnited States\nUSA\n1996\n4000.000\n\n\nUnited States\nUSA\n1997\n4000.000\n\n\nUnited States\nUSA\n1998\n1500.000\n\n\nUnited States\nUSA\n1999\n1500.000\n\n\nUnited States\nUSA\n2000\n1500.000\n\n\nUnited States\nUSA\n2001\n1500.000\n\n\nUnited States\nUSA\n2002\n1500.000\n\n\nUnited States\nUSA\n2003\n1500.000\n\n\nUnited States\nUSA\n2004\n1500.000\n\n\nUnited States\nUSA\n2005\n1500.000\n\n\nUnited States\nUSA\n2006\n1500.000\n\n\nUnited States\nUSA\n2007\n1500.000\n\n\nUnited States\nUSA\n2008\n1500.000\n\n\nUnited States\nUSA\n2009\n1500.000\n\n\nUnited States\nUSA\n2010\n1000.000\n\n\nUnited States\nUSA\n2011\n1000.000\n\n\nUnited States\nUSA\n2012\n1000.000\n\n\nUnited States\nUSA\n2013\n870.000\n\n\nUnited States\nUSA\n2014\n900.000\n\n\nUnited States\nUSA\n2015\n900.000\n\n\nUnited States\nUSA\n2016\n900.000\n\n\nUnited States\nUSA\n2017\n900.000\n\n\nUnited States\nUSA\n2018\n900.000\n\n\nUnited States\nUSA\n2019\n900.000\n\n\nUnited States\nUSA\n2020\n900.000\n\n\nUnited States\nUSA\n2021\n939.234\n\n\nUnited States\nUSA\n2022\n939.234"
  },
  {
    "objectID": "4_EDA_df_lithium.html#df_lithium",
    "href": "4_EDA_df_lithium.html#df_lithium",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "# Read csv file\ndf_production &lt;- read.csv(\"../../data/01-modified-data/clean_lithium-production.csv\")\n\n# Read csv file\ndf_demand &lt;- read.csv(\"../../data/01-modified-data/clean_lithium-demand.csv\")\n\n\ndf_production &lt;- df_production %&gt;% filter(df_production$Code == \"USA\")\n\ndf_production\n\n\nA data.frame: 28 × 4\n\n\nEntity\nCode\nYear\nLithium.production...kt\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\nUnited States\nUSA\n1995\n3500.000\n\n\nUnited States\nUSA\n1996\n4000.000\n\n\nUnited States\nUSA\n1997\n4000.000\n\n\nUnited States\nUSA\n1998\n1500.000\n\n\nUnited States\nUSA\n1999\n1500.000\n\n\nUnited States\nUSA\n2000\n1500.000\n\n\nUnited States\nUSA\n2001\n1500.000\n\n\nUnited States\nUSA\n2002\n1500.000\n\n\nUnited States\nUSA\n2003\n1500.000\n\n\nUnited States\nUSA\n2004\n1500.000\n\n\nUnited States\nUSA\n2005\n1500.000\n\n\nUnited States\nUSA\n2006\n1500.000\n\n\nUnited States\nUSA\n2007\n1500.000\n\n\nUnited States\nUSA\n2008\n1500.000\n\n\nUnited States\nUSA\n2009\n1500.000\n\n\nUnited States\nUSA\n2010\n1000.000\n\n\nUnited States\nUSA\n2011\n1000.000\n\n\nUnited States\nUSA\n2012\n1000.000\n\n\nUnited States\nUSA\n2013\n870.000\n\n\nUnited States\nUSA\n2014\n900.000\n\n\nUnited States\nUSA\n2015\n900.000\n\n\nUnited States\nUSA\n2016\n900.000\n\n\nUnited States\nUSA\n2017\n900.000\n\n\nUnited States\nUSA\n2018\n900.000\n\n\nUnited States\nUSA\n2019\n900.000\n\n\nUnited States\nUSA\n2020\n900.000\n\n\nUnited States\nUSA\n2021\n939.234\n\n\nUnited States\nUSA\n2022\n939.234"
  }
]